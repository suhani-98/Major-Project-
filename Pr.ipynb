{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8cd42b4c013a4ed5aff5760f884cead1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a2a7e73ca40491f8dc3829064b3e0a0",
              "IPY_MODEL_dd59d3d8ad374e70a3e761c88389cd1c",
              "IPY_MODEL_9e6ca4cd879e4bfa9ca5d291cb4d2e15"
            ],
            "layout": "IPY_MODEL_d3a01291b84c4e6fbe230231ea398385"
          }
        },
        "0a2a7e73ca40491f8dc3829064b3e0a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07d19c6ec675408eac71b2ed8eb9598d",
            "placeholder": "​",
            "style": "IPY_MODEL_c845bbe2479a47c09f8887fb47cc1984",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "dd59d3d8ad374e70a3e761c88389cd1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86959533c6984b9f840228d4833e1054",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_04d6340a37e24b8995e4839454b3d401",
            "value": 48
          }
        },
        "9e6ca4cd879e4bfa9ca5d291cb4d2e15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54ac9fe458384a3089450627025ac07d",
            "placeholder": "​",
            "style": "IPY_MODEL_6597ebf9db094ceb850721286e6eabd3",
            "value": " 48.0/48.0 [00:00&lt;00:00, 704B/s]"
          }
        },
        "d3a01291b84c4e6fbe230231ea398385": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07d19c6ec675408eac71b2ed8eb9598d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c845bbe2479a47c09f8887fb47cc1984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86959533c6984b9f840228d4833e1054": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04d6340a37e24b8995e4839454b3d401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54ac9fe458384a3089450627025ac07d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6597ebf9db094ceb850721286e6eabd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0dbe67251c5749ba830d4b3c0f70d322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6aa581f36eb54788a72860d973f47529",
              "IPY_MODEL_ab24f06b37b043b98725cf5e6ef71084",
              "IPY_MODEL_5916877218b742ce9ba97b22b683c70f"
            ],
            "layout": "IPY_MODEL_2601cf244bd949bcb255bba41d3b7340"
          }
        },
        "6aa581f36eb54788a72860d973f47529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8769fb80fc004d5db7fd1d0868b6b22f",
            "placeholder": "​",
            "style": "IPY_MODEL_de5c362cdd63427fa92ca2e0a5f5ff61",
            "value": "config.json: 100%"
          }
        },
        "ab24f06b37b043b98725cf5e6ef71084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7430789e438400da20b47e6edf91d54",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ecd785cfcfe046b69aed4b764f2ea2d8",
            "value": 570
          }
        },
        "5916877218b742ce9ba97b22b683c70f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b04ec5d1b8294596a12f31d01a59c5a8",
            "placeholder": "​",
            "style": "IPY_MODEL_d14b56ca2b4d40c893cbe9c43a3d8b76",
            "value": " 570/570 [00:00&lt;00:00, 10.1kB/s]"
          }
        },
        "2601cf244bd949bcb255bba41d3b7340": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8769fb80fc004d5db7fd1d0868b6b22f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de5c362cdd63427fa92ca2e0a5f5ff61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7430789e438400da20b47e6edf91d54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecd785cfcfe046b69aed4b764f2ea2d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b04ec5d1b8294596a12f31d01a59c5a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d14b56ca2b4d40c893cbe9c43a3d8b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "728a04fe7949401d93c95a686a0281c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b13ae355c23948ce9dca30dd69591f50",
              "IPY_MODEL_928c52e445214674b06852cf6710678b",
              "IPY_MODEL_c6358fc4fe2a4ac6a3c9b9135d9bd117"
            ],
            "layout": "IPY_MODEL_6a5098a51a954c29a7f7f9d7dc9b35fe"
          }
        },
        "b13ae355c23948ce9dca30dd69591f50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96bf69c2abde43f9856b68121196a05f",
            "placeholder": "​",
            "style": "IPY_MODEL_9e440b37a78a45b1b3697ac82e88c796",
            "value": "vocab.txt: 100%"
          }
        },
        "928c52e445214674b06852cf6710678b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3b1a4c1968a44738303761efc32b8cf",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2d2e50a4872411fad5e887233b1117b",
            "value": 231508
          }
        },
        "c6358fc4fe2a4ac6a3c9b9135d9bd117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf0d98e45ca241dc8eaaf0f2fb1da283",
            "placeholder": "​",
            "style": "IPY_MODEL_591c93b0d69b443eb94fd5e313211051",
            "value": " 232k/232k [00:00&lt;00:00, 4.07MB/s]"
          }
        },
        "6a5098a51a954c29a7f7f9d7dc9b35fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96bf69c2abde43f9856b68121196a05f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e440b37a78a45b1b3697ac82e88c796": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3b1a4c1968a44738303761efc32b8cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2d2e50a4872411fad5e887233b1117b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf0d98e45ca241dc8eaaf0f2fb1da283": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "591c93b0d69b443eb94fd5e313211051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a169b223f6f43b4aa7592bcb6bf29f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d19ba64e0e02491388bd28d80cb96e2b",
              "IPY_MODEL_aa6da063623043849a5e0f8ea459983e",
              "IPY_MODEL_4e8beefcff4f4e899551a47ea5b13cd1"
            ],
            "layout": "IPY_MODEL_b697248d4dbd47c6976109bd98e20173"
          }
        },
        "d19ba64e0e02491388bd28d80cb96e2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bc8495230374279aa3b558eb736856b",
            "placeholder": "​",
            "style": "IPY_MODEL_06f3e894fb5640f09f8af466e72e864d",
            "value": "tokenizer.json: 100%"
          }
        },
        "aa6da063623043849a5e0f8ea459983e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f83e599a8ede4004880630334ce8421c",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c304f7503144bf8bd4b9a0fd40e1cc1",
            "value": 466062
          }
        },
        "4e8beefcff4f4e899551a47ea5b13cd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fee99d81d4f40c99d708c02d2c3c331",
            "placeholder": "​",
            "style": "IPY_MODEL_7fdc11057ee845f88403097c09528837",
            "value": " 466k/466k [00:00&lt;00:00, 19.6MB/s]"
          }
        },
        "b697248d4dbd47c6976109bd98e20173": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bc8495230374279aa3b558eb736856b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06f3e894fb5640f09f8af466e72e864d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f83e599a8ede4004880630334ce8421c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c304f7503144bf8bd4b9a0fd40e1cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7fee99d81d4f40c99d708c02d2c3c331": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fdc11057ee845f88403097c09528837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "364b38286c564b48b73a7b339ef8a34d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92cba3b1d55040578428fe8e1ceb442c",
              "IPY_MODEL_2084deb045b84dc0b16861e4b77f6477",
              "IPY_MODEL_6d0fd709c58843d1b34b9e3b10b51b04"
            ],
            "layout": "IPY_MODEL_77ad423fc3374122996253c0ded9a5a6"
          }
        },
        "92cba3b1d55040578428fe8e1ceb442c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_165ea6f064f74394ac4f1188a3271fac",
            "placeholder": "​",
            "style": "IPY_MODEL_6ff9ba96a00b4e32b9ab7cbef9b169b2",
            "value": "model.safetensors: 100%"
          }
        },
        "2084deb045b84dc0b16861e4b77f6477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_743c627a22df411c841e717815ea5bdc",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b59c53c346b14e60ba8ab152deff9f2c",
            "value": 440449768
          }
        },
        "6d0fd709c58843d1b34b9e3b10b51b04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c227d531ee4546c98ecf1dafea2d35b0",
            "placeholder": "​",
            "style": "IPY_MODEL_839c834070274e1f96ccfd0741c4948f",
            "value": " 440M/440M [00:05&lt;00:00, 118MB/s]"
          }
        },
        "77ad423fc3374122996253c0ded9a5a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "165ea6f064f74394ac4f1188a3271fac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ff9ba96a00b4e32b9ab7cbef9b169b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "743c627a22df411c841e717815ea5bdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b59c53c346b14e60ba8ab152deff9f2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c227d531ee4546c98ecf1dafea2d35b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "839c834070274e1f96ccfd0741c4948f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muKlHxOlDXXg",
        "outputId": "f2457771-bd0b-4ab6-ac5b-ea605a6c1035"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zDMM-UPY5Slt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3eb7b0c-06e2-41dc-8549-ea6bf7919469"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/590.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install transformers datasets emoji tldextract wordfreq openpyxl\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer\n",
        "import tldextract\n",
        "import emoji\n",
        "from wordfreq import zipf_frequency\n",
        "\n",
        "# =========================\n",
        "# CONFIG (change if needed)\n",
        "# =========================\n",
        "INPUT_XLSX = \"/content/linkedinFauxPostDetection_Dataset.xlsx\"  # <-- put your path here (upload or from Drive)\n",
        "TEXT_COL   = \"Data\"\n",
        "LABEL_COL  = \"Label (Fake / Real )\"\n",
        "\n",
        "LABEL_MAP = {\"fake\": 1, \"real\": 0}  # Fake=1, Real=0\n",
        "TEST_SIZE = 0.10\n",
        "VAL_SIZE  = 0.10\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "BERT_MODEL_NAME = \"bert-base-uncased\"\n",
        "MAX_LENGTH = 256  # 128/256/512; 256 is a good balance\n",
        "\n",
        "OUTPUT_DIR = \"/content/lfpd_outputs\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"Config OK ✅\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvceSsvG5p_n",
        "outputId": "5df7bcb1-11f1-4d5a-aa48-5bb171b94c65"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config OK ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load\n",
        "df_raw = pd.read_excel(INPUT_XLSX)\n",
        "\n",
        "# Drop unnamed empty columns\n",
        "df = df_raw.loc[:, ~df_raw.columns.astype(str).str.startswith(\"Unnamed\")].copy()\n",
        "\n",
        "# Keep only needed columns\n",
        "assert TEXT_COL in df.columns and LABEL_COL in df.columns, \"Check TEXT_COL and LABEL_COL names.\"\n",
        "df = df[[TEXT_COL, LABEL_COL]].copy()\n",
        "\n",
        "# Drop empty\n",
        "df[TEXT_COL] = df[TEXT_COL].astype(str).str.strip()\n",
        "df[LABEL_COL] = df[LABEL_COL].astype(str).str.strip()\n",
        "\n",
        "df = df[(df[TEXT_COL] != \"\") & (df[LABEL_COL] != \"\")]\n",
        "df = df.drop_duplicates(subset=[TEXT_COL]).reset_index(drop=True)\n",
        "\n",
        "# Normalize label\n",
        "df[LABEL_COL] = df[LABEL_COL].str.lower().str.replace(r\"[^a-z]\", \"\", regex=True)\n",
        "df[\"label\"] = df[LABEL_COL].map(LABEL_MAP)\n",
        "\n",
        "missing = df[\"label\"].isna().sum()\n",
        "if missing > 0:\n",
        "    print(f\"Warning: {missing} rows with unknown labels dropped.\")\n",
        "    df = df[~df[\"label\"].isna()]\n",
        "\n",
        "df[\"label\"] = df[\"label\"].astype(int)\n",
        "df = df.rename(columns={TEXT_COL: \"text\"})\n",
        "df = df[[\"text\", \"label\"]].reset_index(drop=True)\n",
        "\n",
        "print(df.head(3))\n",
        "print(\"Class balance:\", df[\"label\"].value_counts(normalize=True))\n",
        "print(\"Rows after cleaning:\", len(df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFYtWLLI5zky",
        "outputId": "8648f8d1-cf8a-4a17-c481-3e87082d95bf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  label\n",
            "0  🚀 Exciting Internship Opportunity at GAO Tek I...      1\n",
            "1  Urgent hiring! Pay starts at $8,000/week. Send...      1\n",
            "2  Exciting opportunity to earn $10,000/month. No...      1\n",
            "Class balance: label\n",
            "1    0.624655\n",
            "0    0.375345\n",
            "Name: proportion, dtype: float64\n",
            "Rows after cleaning: 2539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "URL_RE = re.compile(r\"https?://[^\\s)]+\", flags=re.I)\n",
        "GOOGLE_FORM_RE = re.compile(r\"https?://(forms\\.gle|docs\\.google\\.com/forms)[^\\s)]+\", re.I)\n",
        "SHORTENER_RE = re.compile(r\"https?://(bit\\.ly|tinyurl\\.com|cutt\\.ly|is\\.gd|rb\\.gy|t\\.co|rebrand\\.ly|linktr\\.ee)/[^\\s)]+\", re.I)\n",
        "EMAIL_RE = re.compile(r\"[A-Za-z0-9._%+-]+@([A-Za-z0-9.-]+\\.[A-Za-z]{2,})\")\n",
        "PHONE_RE_IN = re.compile(r\"(\\+?91[\\-\\s]?)?[6-9]\\d{9}\")\n",
        "\n",
        "HASHTAG_RE = re.compile(r\"#\\w+\")\n",
        "PUNCT_RUN_RE = re.compile(r\"([!?])\\1{2,}\")  # 3+ ! or ?\n",
        "\n",
        "CURRENCY_RE = re.compile(r\"[₹$€]\")\n",
        "MONEY_PER_PERIOD_RE = re.compile(r\"([₹$€]\\s?\\d[\\d,]*(\\.\\d+)?\\s?(\\/|per\\s)(day|week|month|hour))\", re.I)\n",
        "\n",
        "# Keywords (customize easily)\n",
        "URGENCY_WORDS = [\n",
        "    \"urgent\", \"apply now\", \"hurry\", \"last chance\", \"closing soon\", \"limited slots\", \"immediately\", \"asap\"\n",
        "]\n",
        "UPFRONT_FEE_WORDS = [\n",
        "    \"registration fee\", \"security deposit\", \"training fee\", \"pay to apply\", \"processing fee\"\n",
        "]\n",
        "PII_WORDS = [\"aadhaar\", \"aadhar\", \"pan\", \"dob\", \"otp\", \"bank details\", \"credit card\", \"debit card\", \"upi\"]\n",
        "\n",
        "PLATFORM_BYPASS_CUES = [\"dm me\", \"whatsapp\", \"wa.me\", \"t.me\", \"telegram\", \"fill this form\", \"google form\", \"apply via form\"]\n",
        "\n",
        "FREE_EMAIL_DOMAINS = {\"gmail.com\", \"yahoo.com\", \"outlook.com\", \"hotmail.com\", \"rediffmail.com\", \"yopmail.com\"}\n",
        "\n",
        "SUSPICIOUS_TLDS = {\"xyz\", \"top\", \"live\", \"icu\", \"click\"}\n"
      ],
      "metadata": {
        "id": "eGx-JVnx53lN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_emojis(s: str) -> int:\n",
        "    return len(emoji.emoji_list(s))\n",
        "\n",
        "def caps_ratio(s: str) -> float:\n",
        "    letters = [ch for ch in s if ch.isalpha()]\n",
        "    if not letters:\n",
        "        return 0.0\n",
        "    caps = sum(1 for ch in letters if ch.isupper())\n",
        "    return caps / len(letters)\n",
        "\n",
        "def max_punct_run(s: str) -> int:\n",
        "    runs = PUNCT_RUN_RE.findall(s)\n",
        "    # findall returns list of tuples due to capturing; we can compute via lengths directly:\n",
        "    max_run = 0\n",
        "    current = 1\n",
        "    prev = \"\"\n",
        "    for ch in s:\n",
        "        if ch in \"!?\" and ch == prev:\n",
        "            current += 1\n",
        "        else:\n",
        "            max_run = max(max_run, current)\n",
        "            current = 1\n",
        "        prev = ch\n",
        "    max_run = max(max_run, current)\n",
        "    return max_run if max_run >= 3 else 0\n",
        "\n",
        "def oov_ratio(s: str, zipf_threshold: float = 2.5) -> float:\n",
        "    # split to words (keep apostrophes inside words)\n",
        "    tokens = re.findall(r\"[A-Za-z][A-Za-z']+\", s.lower())\n",
        "    if not tokens:\n",
        "        return 0.0\n",
        "    oov = 0\n",
        "    for tok in tokens:\n",
        "        z = zipf_frequency(tok, \"en\")\n",
        "        if z < zipf_threshold:\n",
        "            oov += 1\n",
        "    return oov / len(tokens)\n",
        "\n",
        "def digit_density(s: str) -> float:\n",
        "    if not s:\n",
        "        return 0.0\n",
        "    digits = sum(ch.isdigit() for ch in s)\n",
        "    return digits / len(s)\n",
        "\n",
        "def extract_domains(urls):\n",
        "    domains = []\n",
        "    tlds = []\n",
        "    for u in urls:\n",
        "        ext = tldextract.extract(u)\n",
        "        domain = f\"{ext.domain}.{ext.suffix}\" if ext.suffix else ext.domain\n",
        "        domains.append(domain.lower())\n",
        "        tlds.append(ext.suffix.lower() if ext.suffix else \"\")\n",
        "    return domains, tlds\n",
        "\n",
        "def personal_email_domain_flag(emails):\n",
        "    for e, dom in emails:\n",
        "        if dom.lower() in FREE_EMAIL_DOMAINS:\n",
        "            return 1\n",
        "    return 0\n",
        "\n",
        "def has_uncommon_tld(tlds):\n",
        "    return int(any(t in SUSPICIOUS_TLDS for t in tlds if t))\n",
        "\n",
        "def any_phrase_present(text, phrases):\n",
        "    t = text.lower()\n",
        "    return int(any(p in t for p in phrases))\n",
        "\n",
        "def money_claims_count(text):\n",
        "    return len(MONEY_PER_PERIOD_RE.findall(text))\n",
        "\n",
        "def currency_symbol_count(text):\n",
        "    return len(CURRENCY_RE.findall(text))\n",
        "\n",
        "def url_char_ratio(text, urls):\n",
        "    if not text:\n",
        "        return 0.0\n",
        "    total = sum(len(u) for u in urls)\n",
        "    return total / len(text)\n",
        "\n",
        "def extract_features(text: str) -> dict:\n",
        "    urls = URL_RE.findall(text)\n",
        "    emails = [(m.group(0), m.group(1)) for m in EMAIL_RE.finditer(text)]\n",
        "    phones = PHONE_RE_IN.findall(text)\n",
        "    hashtags = HASHTAG_RE.findall(text)\n",
        "\n",
        "    domains, tlds = extract_domains(urls)\n",
        "\n",
        "    feats = {\n",
        "        \"has_url\": int(len(urls) > 0),\n",
        "        \"num_urls\": len(urls),\n",
        "        \"has_google_form\": int(GOOGLE_FORM_RE.search(text) is not None),\n",
        "        \"num_google_form\": len(GOOGLE_FORM_RE.findall(text)),\n",
        "        \"has_shortener\": int(SHORTENER_RE.search(text) is not None),\n",
        "        \"num_shortener\": len(SHORTENER_RE.findall(text)),\n",
        "\n",
        "        \"has_email\": int(len(emails) > 0),\n",
        "        \"num_emails\": len(emails),\n",
        "        \"has_phone\": int(len(phones) > 0),\n",
        "        \"num_phones\": len(phones),\n",
        "\n",
        "        \"personal_email_domain_flag\": personal_email_domain_flag(emails),\n",
        "        \"uncommon_tld_flag\": has_uncommon_tld(tlds),\n",
        "\n",
        "        \"hashtag_count\": len(hashtags),\n",
        "        \"emoji_count\": count_emojis(text),\n",
        "        \"caps_ratio\": caps_ratio(text),\n",
        "        \"punct_run_len_max\": max_punct_run(text),\n",
        "        \"oov_ratio\": oov_ratio(text, zipf_threshold=2.5),\n",
        "\n",
        "        \"digit_density\": digit_density(text),\n",
        "        \"currency_symbol_count\": currency_symbol_count(text),\n",
        "        \"money_claims_count\": money_claims_count(text),\n",
        "        \"currency_per_period_flag\": int(money_claims_count(text) > 0),\n",
        "\n",
        "        \"urgency_score\": sum(1 for w in URGENCY_WORDS if w in text.lower()),\n",
        "        \"upfront_fee_flag\": any_phrase_present(text, UPFRONT_FEE_WORDS),\n",
        "        \"pii_request_score\": sum(1 for w in PII_WORDS if w in text.lower()),\n",
        "\n",
        "        \"platform_bypass_flag\": any_phrase_present(text, PLATFORM_BYPASS_CUES),\n",
        "\n",
        "        \"url_char_ratio\": url_char_ratio(text, urls),\n",
        "\n",
        "        # Keep first domain & tld (textual, for potential later encoding)\n",
        "        \"primary_domain\": domains[0] if domains else \"\",\n",
        "        \"primary_tld\": tlds[0] if tlds else \"\",\n",
        "    }\n",
        "    return feats\n",
        "\n",
        "# Apply feature extraction\n",
        "features = df[\"text\"].apply(extract_features).apply(pd.Series)\n",
        "df_features = pd.concat([df, features], axis=1)\n",
        "\n",
        "print(\"Feature columns:\", [c for c in df_features.columns if c not in (\"text\", \"label\")][:15], \"...\")\n",
        "print(df_features.head(2))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh1rroHF569I",
        "outputId": "21c87492-d469-42c8-96d7-705ae088aeaf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature columns: ['has_url', 'num_urls', 'has_google_form', 'num_google_form', 'has_shortener', 'num_shortener', 'has_email', 'num_emails', 'has_phone', 'num_phones', 'personal_email_domain_flag', 'uncommon_tld_flag', 'hashtag_count', 'emoji_count', 'caps_ratio'] ...\n",
            "                                                text  label  has_url  \\\n",
            "0  🚀 Exciting Internship Opportunity at GAO Tek I...      1        0   \n",
            "1  Urgent hiring! Pay starts at $8,000/week. Send...      1        0   \n",
            "\n",
            "   num_urls  has_google_form  num_google_form  has_shortener  num_shortener  \\\n",
            "0         0                0                0              0              0   \n",
            "1         0                0                0              0              0   \n",
            "\n",
            "   has_email  num_emails  ...  currency_symbol_count  money_claims_count  \\\n",
            "0          1           1  ...                      0                   0   \n",
            "1          0           0  ...                      1                   1   \n",
            "\n",
            "   currency_per_period_flag  urgency_score  upfront_fee_flag  \\\n",
            "0                         0              1                 0   \n",
            "1                         1              1                 0   \n",
            "\n",
            "   pii_request_score  platform_bypass_flag  url_char_ratio  primary_domain  \\\n",
            "0                  0                     0             0.0                   \n",
            "1                  0                     0             0.0                   \n",
            "\n",
            "   primary_tld  \n",
            "0               \n",
            "1               \n",
            "\n",
            "[2 rows x 30 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First split train+val vs test\n",
        "df_trainval, df_test = train_test_split(\n",
        "    df_features, test_size=TEST_SIZE, stratify=df_features[\"label\"], random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# Now split train vs val from trainval\n",
        "val_frac_of_trainval = VAL_SIZE / (1 - TEST_SIZE)\n",
        "df_train, df_val = train_test_split(\n",
        "    df_trainval, test_size=val_frac_of_trainval, stratify=df_trainval[\"label\"], random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "for name, part in [(\"Train\", df_train), (\"Val\", df_val), (\"Test\", df_test)]:\n",
        "    print(name, \"size:\", len(part), \"| class dist:\", part[\"label\"].value_counts(normalize=True).to_dict())\n",
        "\n",
        "# Save CSVs (text + engineered features + label)\n",
        "train_csv = os.path.join(OUTPUT_DIR, \"train.csv\")\n",
        "val_csv   = os.path.join(OUTPUT_DIR, \"val.csv\")\n",
        "test_csv  = os.path.join(OUTPUT_DIR, \"test.csv\")\n",
        "\n",
        "df_train.to_csv(train_csv, index=False)\n",
        "df_val.to_csv(val_csv, index=False)\n",
        "df_test.to_csv(test_csv, index=False)\n",
        "\n",
        "print(\"Saved:\", train_csv, val_csv, test_csv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSgEGkES6CHg",
        "outputId": "7cef7aa7-4ce3-4c9c-8738-7089cd941ca6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 2031 | class dist: {1: 0.6243229935992122, 0: 0.37567700640078777}\n",
            "Val size: 254 | class dist: {1: 0.6259842519685039, 0: 0.37401574803149606}\n",
            "Test size: 254 | class dist: {1: 0.6259842519685039, 0: 0.37401574803149606}\n",
            "Saved: /content/lfpd_outputs/train.csv /content/lfpd_outputs/val.csv /content/lfpd_outputs/test.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_NAME)\n",
        "\n",
        "def tokenize_batch(texts, max_length=MAX_LENGTH):\n",
        "    enc = tokenizer(\n",
        "        list(texts),\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        return_attention_mask=True\n",
        "    )\n",
        "    return {\n",
        "        \"input_ids\": np.array(enc[\"input_ids\"], dtype=np.int32),\n",
        "        \"attention_mask\": np.array(enc[\"attention_mask\"], dtype=np.int32),\n",
        "    }\n",
        "\n",
        "def pack_npz(df_part, fname_npz):\n",
        "    # Select numeric feature columns (exclude raw text, labels, and non-numeric)\n",
        "    exclude = {\"text\", \"label\", \"primary_domain\", \"primary_tld\"}\n",
        "    numeric_cols = [c for c in df_part.columns if c not in exclude and pd.api.types.is_numeric_dtype(df_part[c])]\n",
        "    feats = df_part[numeric_cols].fillna(0.0).astype(float).values\n",
        "\n",
        "    toks = tokenize_batch(df_part[\"text\"].tolist(), max_length=MAX_LENGTH)\n",
        "    labels = df_part[\"label\"].values.astype(np.int32)\n",
        "\n",
        "    np.savez_compressed(\n",
        "        fname_npz,\n",
        "        input_ids=toks[\"input_ids\"],\n",
        "        attention_mask=toks[\"attention_mask\"],\n",
        "        features=feats,\n",
        "        labels=labels,\n",
        "        feature_names=np.array(numeric_cols)\n",
        "    )\n",
        "    return numeric_cols\n",
        "\n",
        "train_npz = os.path.join(OUTPUT_DIR, \"bert_tokenized_train.npz\")\n",
        "val_npz   = os.path.join(OUTPUT_DIR, \"bert_tokenized_val.npz\")\n",
        "test_npz  = os.path.join(OUTPUT_DIR, \"bert_tokenized_test.npz\")\n",
        "\n",
        "feat_cols_train = pack_npz(df_train, train_npz)\n",
        "feat_cols_val   = pack_npz(df_val,   val_npz)\n",
        "feat_cols_test  = pack_npz(df_test,  test_npz)\n",
        "\n",
        "print(\"Saved NPZs:\", train_npz, val_npz, test_npz)\n",
        "print(\"Numeric feature columns used:\", len(feat_cols_train))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313,
          "referenced_widgets": [
            "8cd42b4c013a4ed5aff5760f884cead1",
            "0a2a7e73ca40491f8dc3829064b3e0a0",
            "dd59d3d8ad374e70a3e761c88389cd1c",
            "9e6ca4cd879e4bfa9ca5d291cb4d2e15",
            "d3a01291b84c4e6fbe230231ea398385",
            "07d19c6ec675408eac71b2ed8eb9598d",
            "c845bbe2479a47c09f8887fb47cc1984",
            "86959533c6984b9f840228d4833e1054",
            "04d6340a37e24b8995e4839454b3d401",
            "54ac9fe458384a3089450627025ac07d",
            "6597ebf9db094ceb850721286e6eabd3",
            "0dbe67251c5749ba830d4b3c0f70d322",
            "6aa581f36eb54788a72860d973f47529",
            "ab24f06b37b043b98725cf5e6ef71084",
            "5916877218b742ce9ba97b22b683c70f",
            "2601cf244bd949bcb255bba41d3b7340",
            "8769fb80fc004d5db7fd1d0868b6b22f",
            "de5c362cdd63427fa92ca2e0a5f5ff61",
            "e7430789e438400da20b47e6edf91d54",
            "ecd785cfcfe046b69aed4b764f2ea2d8",
            "b04ec5d1b8294596a12f31d01a59c5a8",
            "d14b56ca2b4d40c893cbe9c43a3d8b76",
            "728a04fe7949401d93c95a686a0281c9",
            "b13ae355c23948ce9dca30dd69591f50",
            "928c52e445214674b06852cf6710678b",
            "c6358fc4fe2a4ac6a3c9b9135d9bd117",
            "6a5098a51a954c29a7f7f9d7dc9b35fe",
            "96bf69c2abde43f9856b68121196a05f",
            "9e440b37a78a45b1b3697ac82e88c796",
            "e3b1a4c1968a44738303761efc32b8cf",
            "c2d2e50a4872411fad5e887233b1117b",
            "cf0d98e45ca241dc8eaaf0f2fb1da283",
            "591c93b0d69b443eb94fd5e313211051",
            "8a169b223f6f43b4aa7592bcb6bf29f2",
            "d19ba64e0e02491388bd28d80cb96e2b",
            "aa6da063623043849a5e0f8ea459983e",
            "4e8beefcff4f4e899551a47ea5b13cd1",
            "b697248d4dbd47c6976109bd98e20173",
            "9bc8495230374279aa3b558eb736856b",
            "06f3e894fb5640f09f8af466e72e864d",
            "f83e599a8ede4004880630334ce8421c",
            "3c304f7503144bf8bd4b9a0fd40e1cc1",
            "7fee99d81d4f40c99d708c02d2c3c331",
            "7fdc11057ee845f88403097c09528837"
          ]
        },
        "id": "riL6vWgk6DbI",
        "outputId": "4a8492db-fdc6-4be7-b38b-9fa788220e80"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8cd42b4c013a4ed5aff5760f884cead1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0dbe67251c5749ba830d4b3c0f70d322"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "728a04fe7949401d93c95a686a0281c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a169b223f6f43b4aa7592bcb6bf29f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved NPZs: /content/lfpd_outputs/bert_tokenized_train.npz /content/lfpd_outputs/bert_tokenized_val.npz /content/lfpd_outputs/bert_tokenized_test.npz\n",
            "Numeric feature columns used: 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load(os.path.join(OUTPUT_DIR, \"bert_tokenized_train.npz\"), allow_pickle=True)\n",
        "print(\"NPZ keys:\", list(data.keys()))\n",
        "print(\"Shapes:\",\n",
        "      data[\"input_ids\"].shape,\n",
        "      data[\"attention_mask\"].shape,\n",
        "      data[\"features\"].shape,\n",
        "      data[\"labels\"].shape)\n",
        "print(\"First 5 feature names:\", data[\"feature_names\"][:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIHxhrNO6L6b",
        "outputId": "48d651d4-5aad-4490-dda2-8f400e429bb4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NPZ keys: ['input_ids', 'attention_mask', 'features', 'labels', 'feature_names']\n",
            "Shapes: (2031, 256) (2031, 256) (2031, 26) (2031,)\n",
            "First 5 feature names: ['has_url' 'num_urls' 'has_google_form' 'num_google_form' 'has_shortener']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing done\n",
        "\n",
        "modelling start\n"
      ],
      "metadata": {
        "id": "3eIFxIXEPSW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install transformers scikit-learn torchmetrics\n",
        "\n",
        "import os, json, math, random, time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertModel, AutoConfig\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.optim import AdamW\n",
        "from torchmetrics.functional import accuracy\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", DEVICE)\n",
        "\n",
        "OUTPUT_DIR = \"/content/lfpd_outputs\"\n",
        "TRAIN_NPZ = os.path.join(OUTPUT_DIR, \"bert_tokenized_train.npz\")\n",
        "VAL_NPZ   = os.path.join(OUTPUT_DIR, \"bert_tokenized_val.npz\")\n",
        "TEST_NPZ  = os.path.join(OUTPUT_DIR, \"bert_tokenized_test.npz\")\n",
        "\n",
        "BERT_MODEL_NAME = \"bert-base-uncased\"\n",
        "NUM_CLASSES = 2  # Real(0), Fake(1)\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "if DEVICE == \"cuda\":\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "print(\"Paths OK\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47pR-9F16Pwz",
        "outputId": "5157437c-2dd3-4f5b-a9db-4eac26af04da"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/983.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.0/983.0 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDevice: cpu\n",
            "Paths OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_npz(path):\n",
        "    z = np.load(path, allow_pickle=True)\n",
        "    return {\n",
        "        \"input_ids\": z[\"input_ids\"],\n",
        "        \"attention_mask\": z[\"attention_mask\"],\n",
        "        \"features\": z[\"features\"].astype(np.float32),\n",
        "        \"labels\": z[\"labels\"],\n",
        "        \"feature_names\": [str(x) for x in z[\"feature_names\"]],\n",
        "    }\n",
        "\n",
        "train = load_npz(TRAIN_NPZ)\n",
        "val   = load_npz(VAL_NPZ)\n",
        "test  = load_npz(TEST_NPZ)\n",
        "\n",
        "print(\"Train shapes:\",\n",
        "      train[\"input_ids\"].shape, train[\"attention_mask\"].shape,\n",
        "      train[\"features\"].shape, train[\"labels\"].shape)\n",
        "\n",
        "# Standardize features (fit on train, apply to all)\n",
        "scaler = StandardScaler()\n",
        "train_feats_std = scaler.fit_transform(train[\"features\"])\n",
        "val_feats_std   = scaler.transform(val[\"features\"])\n",
        "test_feats_std  = scaler.transform(test[\"features\"])\n",
        "\n",
        "# For later inference, you may want to persist scaler params\n",
        "scaler_params = {\n",
        "    \"mean\": scaler.mean_.tolist(),\n",
        "    \"scale\": scaler.scale_.tolist(),\n",
        "    \"feature_names\": train[\"feature_names\"],\n",
        "}\n",
        "with open(os.path.join(OUTPUT_DIR, \"feature_scaler.json\"), \"w\") as f:\n",
        "    json.dump(scaler_params, f)\n",
        "\n",
        "print(\"Standardization done. Feature count:\", train_feats_std.shape[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHjIvWrn6Wmc",
        "outputId": "10850c0e-b505-4edb-863e-05fa0987101f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shapes: (2031, 256) (2031, 256) (2031, 26) (2031,)\n",
            "Standardization done. Feature count: 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LFPDTokenizedDataset(Dataset):\n",
        "    def __init__(self, ids, mask, feats, labels):\n",
        "        self.input_ids = torch.tensor(ids, dtype=torch.long)\n",
        "        self.attention_mask = torch.tensor(mask, dtype=torch.long)\n",
        "        self.features = torch.tensor(feats, dtype=torch.float)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.labels.size(0)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"input_ids\": self.input_ids[idx],\n",
        "            \"attention_mask\": self.attention_mask[idx],\n",
        "            \"features\": self.features[idx],\n",
        "            \"labels\": self.labels[idx],\n",
        "        }\n",
        "\n",
        "train_ds = LFPDTokenizedDataset(train[\"input_ids\"], train[\"attention_mask\"], train_feats_std, train[\"labels\"])\n",
        "val_ds   = LFPDTokenizedDataset(val[\"input_ids\"],   val[\"attention_mask\"],   val_feats_std,   val[\"labels\"])\n",
        "test_ds  = LFPDTokenizedDataset(test[\"input_ids\"],  test[\"attention_mask\"],  test_feats_std,  test[\"labels\"])\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, pin_memory=(DEVICE==\"cuda\"))\n",
        "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, pin_memory=(DEVICE==\"cuda\"))\n",
        "test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, pin_memory=(DEVICE==\"cuda\"))\n",
        "print(\"DataLoaders ready.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tE3JZsvz6ZU8",
        "outputId": "1e766069-5849-4756-db47-16c927c55995"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataLoaders ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BertFeatsClassifier(nn.Module):\n",
        "    def __init__(self, bert_name: str, feature_dim: int, num_classes: int = 2,\n",
        "                 feat_hidden: int = 64, dropout_p: float = 0.2, freeze_bert: bool = False):\n",
        "        super().__init__()\n",
        "        self.config = AutoConfig.from_pretrained(bert_name)\n",
        "        self.bert = BertModel.from_pretrained(bert_name)\n",
        "\n",
        "        # Optional: freeze BERT encoder for speed (you can set False to fine-tune fully)\n",
        "        if freeze_bert:\n",
        "            for p in self.bert.parameters():\n",
        "                p.requires_grad = False\n",
        "\n",
        "        bert_out_dim = self.config.hidden_size  # 768 for bert-base\n",
        "        self.text_dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "        # Small MLP over side features\n",
        "        self.feat_net = nn.Sequential(\n",
        "            nn.Linear(feature_dim, feat_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_p),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(bert_out_dim + feat_hidden, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_p),\n",
        "            nn.Linear(128, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, features):\n",
        "        out = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        # Use pooled_output (CLS) — already passed through a tanh dense layer inside BERT\n",
        "        pooled = self.text_dropout(out.pooler_output)  # [B, 768]\n",
        "\n",
        "        feat_repr = self.feat_net(features)            # [B, feat_hidden]\n",
        "        concat = torch.cat([pooled, feat_repr], dim=1) # [B, 768+feat_hidden]\n",
        "        logits = self.classifier(concat)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "943SK6LY6bp0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute class weights from training labels (Real=0, Fake=1)\n",
        "class_counts = np.bincount(train[\"labels\"], minlength=NUM_CLASSES)\n",
        "class_weights = (class_counts.sum() / (NUM_CLASSES * class_counts + 1e-8)).astype(np.float32)\n",
        "print(\"Class counts:\", class_counts, \" -> weights:\", class_weights)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=torch.tensor(class_weights, dtype=torch.float, device=DEVICE))\n",
        "\n",
        "def evaluate(model, data_loader):\n",
        "    model.eval()\n",
        "    all_logits, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "            attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
        "            features = batch[\"features\"].to(DEVICE)\n",
        "            labels = batch[\"labels\"].to(DEVICE)\n",
        "\n",
        "            logits = model(input_ids, attention_mask, features)\n",
        "            all_logits.append(logits.cpu().numpy())\n",
        "            all_labels.append(labels.cpu().numpy())\n",
        "\n",
        "    all_logits = np.concatenate(all_logits, axis=0)\n",
        "    all_labels = np.concatenate(all_labels, axis=0)\n",
        "    preds = all_logits.argmax(axis=1)\n",
        "\n",
        "    p, r, f1, _ = precision_recall_fscore_support(all_labels, preds, labels=[0,1], average=None, zero_division=0)\n",
        "    macro_f1 = f1.mean()\n",
        "    acc = (preds == all_labels).mean()\n",
        "\n",
        "    report = {\n",
        "        \"acc\": acc,\n",
        "        \"macro_f1\": macro_f1,\n",
        "        \"per_class\": {\n",
        "            \"real\": {\"precision\": float(p[0]), \"recall\": float(r[0]), \"f1\": float(f1[0])},\n",
        "            \"fake\": {\"precision\": float(p[1]), \"recall\": float(r[1]), \"f1\": float(f1[1])},\n",
        "        }\n",
        "    }\n",
        "    return report, preds, all_labels, all_logits\n",
        "\n",
        "def pretty_report(tag, rep):\n",
        "    print(f\"\\n[{tag}] acc={rep['acc']:.4f} | macro_f1={rep['macro_f1']:.4f} | \"\n",
        "          f\"Fake-F1={rep['per_class']['fake']['f1']:.4f} (P={rep['per_class']['fake']['precision']:.4f}, \"\n",
        "          f\"R={rep['per_class']['fake']['recall']:.4f})\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_chiSAP66eIj",
        "outputId": "dc9a071b-f686-4a5c-872a-28b4cce671b5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class counts: [ 763 1268]  -> weights: [1.3309306 0.8008675]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_dim = train_feats_std.shape[1]\n",
        "model = BertFeatsClassifier(\n",
        "    bert_name=BERT_MODEL_NAME,\n",
        "    feature_dim=feature_dim,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    feat_hidden=64,\n",
        "    dropout_p=0.2,\n",
        "    freeze_bert=False  # set True to train faster (but lower accuracy)\n",
        ").to(DEVICE)\n",
        "\n",
        "EPOCHS = 5\n",
        "LR = 2e-5\n",
        "WD = 0.01\n",
        "optimizer = AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
        "\n",
        "best_val_fake_f1 = -1.0\n",
        "patience = 2\n",
        "no_improve = 0\n",
        "best_path = os.path.join(OUTPUT_DIR, \"best_model.pt\")\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
        "        features = batch[\"features\"].to(DEVICE)\n",
        "        labels = batch[\"labels\"].to(DEVICE)\n",
        "\n",
        "        logits = model(input_ids, attention_mask, features)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    train_rep, _, _, _ = evaluate(model, train_loader)\n",
        "    val_rep, _, _, _ = evaluate(model, val_loader)\n",
        "    pretty_report(f\"Epoch {epoch} / Train\", train_rep)\n",
        "    pretty_report(f\"Epoch {epoch} / Val\", val_rep)\n",
        "\n",
        "    val_fake_f1 = val_rep[\"per_class\"][\"fake\"][\"f1\"]\n",
        "\n",
        "    # Early stopping on Val Fake-F1\n",
        "    if val_fake_f1 > best_val_fake_f1:\n",
        "        best_val_fake_f1 = val_fake_f1\n",
        "        no_improve = 0\n",
        "        torch.save(model.state_dict(), best_path)\n",
        "        print(f\"✅ Saved new best model (Val Fake-F1={best_val_fake_f1:.4f}) -> {best_path}\")\n",
        "    else:\n",
        "        no_improve += 1\n",
        "        print(f\"⚠️ No improvement [{no_improve}/{patience}]\")\n",
        "        if no_improve >= patience:\n",
        "            print(\"⏹️ Early stopping.\")\n",
        "            break\n",
        "\n",
        "print(\"Training done.\")"
      ],
      "metadata": {
        "id": "_lV2F7NJ64HK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "364b38286c564b48b73a7b339ef8a34d",
            "92cba3b1d55040578428fe8e1ceb442c",
            "2084deb045b84dc0b16861e4b77f6477",
            "6d0fd709c58843d1b34b9e3b10b51b04",
            "77ad423fc3374122996253c0ded9a5a6",
            "165ea6f064f74394ac4f1188a3271fac",
            "6ff9ba96a00b4e32b9ab7cbef9b169b2",
            "743c627a22df411c841e717815ea5bdc",
            "b59c53c346b14e60ba8ab152deff9f2c",
            "c227d531ee4546c98ecf1dafea2d35b0",
            "839c834070274e1f96ccfd0741c4948f"
          ]
        },
        "outputId": "22440195-c644-4ebb-ee66-be363224d81d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "364b38286c564b48b73a7b339ef8a34d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best checkpoint\n",
        "best_model = BertFeatsClassifier(\n",
        "    bert_name=BERT_MODEL_NAME,\n",
        "    feature_dim=feature_dim,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    feat_hidden=64,\n",
        "    dropout_p=0.2,\n",
        "    freeze_bert=False\n",
        ").to(DEVICE)\n",
        "\n",
        "best_model.load_state_dict(torch.load(best_path, map_location=DEVICE))\n",
        "\n",
        "test_rep, test_pred, test_true, test_logits = evaluate(best_model, test_loader)\n",
        "pretty_report(\"TEST\", test_rep)\n",
        "\n",
        "print(\"\\nClassification report (per class):\")\n",
        "print(classification_report(test_true, test_pred, target_names=[\"Real(0)\",\"Fake(1)\"], digits=4))\n",
        "\n",
        "print(\"Confusion matrix [[TN, FP],[FN, TP]]:\")\n",
        "print(confusion_matrix(test_true, test_pred, labels=[0,1]))\n"
      ],
      "metadata": {
        "id": "mZnxxUhqN0HD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute slice metrics using feature flags in VAL set (you can switch to TEST similarly)\n",
        "# We'll re-open val NPZ to access feature_names & values\n",
        "val_z = np.load(VAL_NPZ, allow_pickle=True)\n",
        "feature_names = [str(x) for x in val_z[\"feature_names\"]]\n",
        "val_feats = val_feats_std  # standardized features we used\n",
        "\n",
        "def idx_of(name):\n",
        "    return feature_names.index(name) if name in feature_names else None\n",
        "\n",
        "flag_names = [\"has_google_form\", \"has_shortener\", \"money_claims_count\", \"platform_bypass_flag\"]\n",
        "flag_idx = {fn: idx_of(fn) for fn in flag_names}\n",
        "flag_idx\n",
        "\n",
        "# Make predictions on VAL to compute slice metrics\n",
        "best_model.eval()\n",
        "all_preds, all_labels, all_flags = [], [], {}\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
        "        features = batch[\"features\"].to(DEVICE)\n",
        "        labels = batch[\"labels\"]\n",
        "\n",
        "        logits = best_model(input_ids, attention_mask, features)\n",
        "        preds = logits.argmax(dim=1).cpu()\n",
        "\n",
        "        all_preds.append(preds.numpy())\n",
        "        all_labels.append(labels.numpy())\n",
        "\n",
        "all_preds = np.concatenate(all_preds)\n",
        "all_labels = np.concatenate(all_labels)\n",
        "\n",
        "# Reconstruct flags aligned to val order\n",
        "val_flags = {fn: (val_feats[:, flag_idx[fn]] if flag_idx[fn] is not None else None) for fn in flag_names}\n",
        "\n",
        "def slice_report(name, mask):\n",
        "    y_true = all_labels[mask]\n",
        "    y_pred = all_preds[mask]\n",
        "    if len(y_true) == 0:\n",
        "        print(f\"[Slice: {name}] No samples.\")\n",
        "        return\n",
        "    p, r, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=None, labels=[0,1], zero_division=0)\n",
        "    print(f\"[Slice: {name}] size={len(y_true)} | Fake-F1={f1[1]:.4f} (P={p[1]:.4f}, R={r[1]:.4f}) | Acc={(y_pred==y_true).mean():.4f}\")\n",
        "\n",
        "for name in flag_names:\n",
        "    idx = flag_idx[name]\n",
        "    if idx is None:\n",
        "        print(f\"[Slice: {name}] Not in features.\")\n",
        "        continue\n",
        "    # For binary flags: >0 considered True; for count features: >0 means present\n",
        "    mask = val_feats[:, idx] > 0\n",
        "    slice_report(name, mask)\n"
      ],
      "metadata": {
        "id": "3S7oEBu5N7SB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference (single post → prediction)\n",
        "\n",
        "raw post text input lo\n",
        "\n",
        "same feature extractor use karo\n",
        "\n",
        "scaler apply + BERT tokenize\n",
        "\n",
        "best model load karke label + probs + top signals return\n"
      ],
      "metadata": {
        "id": "wbvcLzW-Wnjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json, numpy as np, torch\n",
        "from transformers import AutoTokenizer\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Reuse: BertFeatsClassifier class, extract_features(), tokenizer config, feature_names from NPZ/scaler json\n",
        "device = DEVICE if 'DEVICE' in globals() else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load artifacts\n",
        "with open(f\"{OUTPUT_DIR}/feature_scaler.json\", \"r\") as f:\n",
        "    scaler_params = json.load(f)\n",
        "feature_names_serving = scaler_params[\"feature_names\"]\n",
        "scaler_mean = np.array(scaler_params[\"mean\"], dtype=np.float32)\n",
        "scaler_scale = np.array(scaler_params[\"scale\"], dtype=np.float32)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_NAME)\n",
        "feature_dim = len(feature_names_serving)\n",
        "\n",
        "infer_model = BertFeatsClassifier(\n",
        "    bert_name=BERT_MODEL_NAME, feature_dim=feature_dim,\n",
        "    num_classes=2, feat_hidden=64, dropout_p=0.2, freeze_bert=False\n",
        ").to(device)\n",
        "infer_model.load_state_dict(torch.load(f\"{OUTPUT_DIR}/best_model.pt\", map_location=device))\n",
        "infer_model.eval()\n",
        "\n",
        "def standardize_features(vec_np: np.ndarray) -> np.ndarray:\n",
        "    # vec_np shape: (feature_dim,)\n",
        "    return (vec_np - scaler_mean) / (scaler_scale + 1e-8)\n",
        "\n",
        "def vectorize_features(feat_dict: dict) -> np.ndarray:\n",
        "    # Only numeric features that were used during training\n",
        "    vals = []\n",
        "    for name in feature_names_serving:\n",
        "        v = feat_dict.get(name, 0.0)\n",
        "        vals.append(float(v))\n",
        "    return np.array(vals, dtype=np.float32)\n",
        "\n",
        "def tokenize_single(text: str, max_length=256):\n",
        "    enc = tokenizer(\n",
        "        [text], padding=\"max_length\", truncation=True, max_length=max_length, return_attention_mask=True\n",
        "    )\n",
        "    input_ids = torch.tensor(enc[\"input_ids\"], dtype=torch.long)\n",
        "    attention_mask = torch.tensor(enc[\"attention_mask\"], dtype=torch.long)\n",
        "    return input_ids, attention_mask\n",
        "\n",
        "def top_signals(feats: dict, k=3):\n",
        "    # Heuristic picks: choose binary/count features that are 1 or >0 and most indicative\n",
        "    priority = [\n",
        "        \"has_google_form\", \"money_claims_count\", \"platform_bypass_flag\",\n",
        "        \"has_shortener\", \"currency_per_period_flag\", \"personal_email_domain_flag\",\n",
        "        \"upfront_fee_flag\", \"pii_request_score\", \"uncommon_tld_flag\", \"has_email\", \"has_phone\"\n",
        "    ]\n",
        "    present = []\n",
        "    for p in priority:\n",
        "        if p in feats:\n",
        "            try:\n",
        "                val = float(feats[p])\n",
        "                if val > 0:\n",
        "                    present.append(p)\n",
        "            except:\n",
        "                pass\n",
        "    return present[:k]\n",
        "\n",
        "def predict_post(text: str, threshold: float = 0.50):\n",
        "    # 1) engineered features\n",
        "    feats = extract_features(text)\n",
        "    vec = vectorize_features(feats)\n",
        "    vec_std = standardize_features(vec)\n",
        "\n",
        "    # 2) tokenize\n",
        "    input_ids, attention_mask = tokenize_single(text, max_length=MAX_LENGTH)\n",
        "\n",
        "    # 3) to device\n",
        "    input_ids = input_ids.to(device)\n",
        "    attention_mask = attention_mask.to(device)\n",
        "    feats_t = torch.tensor(vec_std, dtype=torch.float, device=device).unsqueeze(0)\n",
        "\n",
        "    # 4) forward\n",
        "    with torch.no_grad():\n",
        "        logits = infer_model(input_ids, attention_mask, feats_t)\n",
        "        probs = F.softmax(logits, dim=1).cpu().numpy()[0]\n",
        "    prob_real, prob_fake = float(probs[0]), float(probs[1])\n",
        "    label = \"fake\" if prob_fake >= threshold else \"real\"\n",
        "\n",
        "    return {\n",
        "        \"label\": label,\n",
        "        \"prob_fake\": prob_fake,\n",
        "        \"prob_real\": prob_real,\n",
        "        \"threshold_used\": threshold,\n",
        "        \"top_signals\": top_signals(feats, k=3)\n",
        "    }\n",
        "\n",
        "# Demo\n",
        "demo_text = \"Urgent hiring! Earn $8000/week. Fill this Google Form: https://forms.gle/xyz and WhatsApp at wa.me/911234567890\"\n",
        "print(predict_post(demo_text, threshold=0.50))\n"
      ],
      "metadata": {
        "id": "VY8fyHxASi0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# Use validation logits by re-running evaluate() but grab logits for probability\n",
        "infer_model.eval()\n",
        "all_logits, all_labels = [], []\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        ids = batch[\"input_ids\"].to(device)\n",
        "        mask = batch[\"attention_mask\"].to(device)\n",
        "        feats = batch[\"features\"].to(device)\n",
        "        labels = batch[\"labels\"].cpu().numpy()\n",
        "        logits = infer_model(ids, mask, feats).cpu().numpy()\n",
        "\n",
        "        all_logits.append(logits)\n",
        "        all_labels.append(labels)\n",
        "\n",
        "all_logits = np.concatenate(all_logits, axis=0)\n",
        "all_labels = np.concatenate(all_labels, axis=0)\n",
        "probs = np.exp(all_logits - all_logits.max(axis=1, keepdims=True))\n",
        "probs = probs / probs.sum(axis=1, keepdims=True)\n",
        "prob_fake = probs[:, 1]\n",
        "\n",
        "def evaluate_threshold(t):\n",
        "    preds = (prob_fake >= t).astype(int)  # 1 = Fake\n",
        "    p, r, f1, _ = precision_recall_fscore_support(all_labels, preds, labels=[0,1], average=None, zero_division=0)\n",
        "    return {\n",
        "        \"thr\": t,\n",
        "        \"acc\": (preds == all_labels).mean(),\n",
        "        \"macro_f1\": float(f1.mean()),\n",
        "        \"fake_p\": float(p[1]), \"fake_r\": float(r[1]), \"fake_f1\": float(f1[1]),\n",
        "        \"real_p\": float(p[0]), \"real_r\": float(r[0]), \"real_f1\": float(f1[0]),\n",
        "    }\n",
        "\n",
        "candidates = np.linspace(0.30, 0.70, 21)\n",
        "results = [evaluate_threshold(float(t)) for t in candidates]\n",
        "\n",
        "# Strategy 1: pick max Fake-F1\n",
        "best_by_fake_f1 = max(results, key=lambda x: x[\"fake_f1\"])\n",
        "print(\"Best by Fake-F1:\", best_by_fake_f1)\n",
        "\n",
        "# Strategy 2: enforce Fake precision >= 0.70 then maximize recall\n",
        "feasible = [r for r in results if r[\"fake_p\"] >= 0.70]\n",
        "best_prec_constraint = max(feasible, key=lambda x: x[\"fake_r\"]) if feasible else best_by_fake_f1\n",
        "print(\"Best with Fake-P>=0.70 (max recall):\", best_prec_constraint)\n",
        "\n",
        "# (Optional) pretty table\n",
        "pd.DataFrame(results).round(4).sort_values(\"fake_f1\", ascending=False).head(10)\n"
      ],
      "metadata": {
        "id": "RGZoCDiBW00H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Rebuild test predictions with probs for export\n",
        "infer_model.eval()\n",
        "t_logits, t_labels = [], []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        ids = batch[\"input_ids\"].to(device)\n",
        "        mask = batch[\"attention_mask\"].to(device)\n",
        "        feats = batch[\"features\"].to(device)\n",
        "        labels = batch[\"labels\"].cpu().numpy()\n",
        "        logits = infer_model(ids, mask, feats).cpu().numpy()\n",
        "        t_logits.append(logits); t_labels.append(labels)\n",
        "\n",
        "t_logits = np.concatenate(t_logits, axis=0)\n",
        "t_labels = np.concatenate(t_labels, axis=0)\n",
        "t_probs = np.exp(t_logits - t_logits.max(axis=1, keepdims=True))\n",
        "t_probs = t_probs / t_probs.sum(axis=1, keepdims=True)\n",
        "t_pred = t_probs.argmax(axis=1)\n",
        "\n",
        "# Load raw test.csv to get original text and feature flags\n",
        "test_csv = pd.read_csv(f\"{OUTPUT_DIR}/test.csv\")\n",
        "assert len(test_csv) == len(t_labels), \"Mismatch between test csv and loader order.\"\n",
        "\n",
        "df_err = pd.DataFrame({\n",
        "    \"text\": test_csv[\"text\"],\n",
        "    \"true_label\": t_labels,\n",
        "    \"pred_label\": t_pred,\n",
        "    \"prob_real\": t_probs[:,0],\n",
        "    \"prob_fake\": t_probs[:,1],\n",
        "    \"has_google_form\": test_csv.get(\"has_google_form\", 0),\n",
        "    \"has_shortener\": test_csv.get(\"has_shortener\", 0),\n",
        "    \"money_claims_count\": test_csv.get(\"money_claims_count\", 0),\n",
        "    \"platform_bypass_flag\": test_csv.get(\"platform_bypass_flag\", 0),\n",
        "    \"personal_email_domain_flag\": test_csv.get(\"personal_email_domain_flag\", 0),\n",
        "    \"uncommon_tld_flag\": test_csv.get(\"uncommon_tld_flag\", 0),\n",
        "    \"upfront_fee_flag\": test_csv.get(\"upfront_fee_flag\", 0),\n",
        "    \"pii_request_score\": test_csv.get(\"pii_request_score\", 0),\n",
        "})\n",
        "\n",
        "df_fp = df_err[(df_err.true_label==0) & (df_err.pred_label==1)].copy()  # predicted Fake but Real\n",
        "df_fn = df_err[(df_err.true_label==1) & (df_err.pred_label==0)].copy()  # predicted Real but Fake\n",
        "\n",
        "fp_path = f\"{OUTPUT_DIR}/errors_false_positives.csv\"\n",
        "fn_path = f\"{OUTPUT_DIR}/errors_false_negatives.csv\"\n",
        "df_fp.to_csv(fp_path, index=False)\n",
        "df_fn.to_csv(fn_path, index=False)\n",
        "\n",
        "print(\"Saved:\")\n",
        "print(\"FP ->\", fp_path, \" | count:\", len(df_fp))\n",
        "print(\"FN ->\", fn_path, \" | count:\", len(df_fn))\n",
        "df_fp.head(2), df_fn.head(2)\n"
      ],
      "metadata": {
        "id": "bnor7xhTW7uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "more_flags = [\n",
        "    \"personal_email_domain_flag\", \"uncommon_tld_flag\", \"upfront_fee_flag\",\n",
        "    \"pii_request_score\", \"has_email\", \"has_phone\"\n",
        "]\n",
        "\n",
        "# Reuse validation probs/preds from Cell J\n",
        "val_flags_full = {fn: (val_feats[:, feature_names.index(fn)] if fn in feature_names else None)\n",
        "                  for fn in more_flags}\n",
        "\n",
        "def slice_eval_by_flag(flag_name, greater_than_zero=True):\n",
        "    idx = feature_names.index(flag_name) if flag_name in feature_names else None\n",
        "    if idx is None:\n",
        "        print(f\"[Slice: {flag_name}] Not found in feature_names.\")\n",
        "        return\n",
        "    mask = (val_feats[:, idx] > 0) if greater_than_zero else (val_feats[:, idx] == 0)\n",
        "    y_true = all_labels[mask]\n",
        "    y_pred = (prob_fake[mask] >= 0.5).astype(int)  # default threshold here; swap to tuned if you want\n",
        "    if len(y_true) == 0:\n",
        "        print(f\"[Slice: {flag_name}] No samples.\")\n",
        "        return\n",
        "    p, r, f1, _ = precision_recall_fscore_support(y_true, y_pred, labels=[0,1], average=None, zero_division=0)\n",
        "    print(f\"[Slice: {flag_name}] size={len(y_true)} | Fake-F1={f1[1]:.4f} (P={p[1]:.4f}, R={r[1]:.4f}) | Acc={(y_pred==y_true).mean():.4f}\")\n",
        "\n",
        "for name in more_flags:\n",
        "    slice_eval_by_flag(name, greater_than_zero=True)\n"
      ],
      "metadata": {
        "id": "iKztDTkXXD8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil, datetime, json\n",
        "\n",
        "version = datetime.datetime.now().strftime(\"v%Y%m%d_%H%M\")\n",
        "bundle_dir = f\"{OUTPUT_DIR}/bundle_{version}\"\n",
        "os.makedirs(bundle_dir, exist_ok=True)\n",
        "\n",
        "# Copy model + scaler\n",
        "shutil.copyfile(f\"{OUTPUT_DIR}/best_model.pt\", f\"{bundle_dir}/best_model.pt\")\n",
        "shutil.copyfile(f\"{OUTPUT_DIR}/feature_scaler.json\", f\"{bundle_dir}/feature_scaler.json\")\n",
        "\n",
        "# Save a small config\n",
        "cfg = {\n",
        "    \"bert_model\": BERT_MODEL_NAME,\n",
        "    \"max_length\": int(MAX_LENGTH),\n",
        "    \"feature_names\": feature_names_serving,\n",
        "    \"exported_at\": version\n",
        "}\n",
        "with open(f\"{bundle_dir}/config.json\", \"w\") as f:\n",
        "    json.dump(cfg, f, indent=2)\n",
        "\n",
        "print(\"Exported bundle ->\", bundle_dir)\n"
      ],
      "metadata": {
        "id": "hA3ztD2_XFqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install fastapi uvicorn\n",
        "\n",
        "import uvicorn\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "# Load from bundle (update to your bundle path)\n",
        "BUNDLE = bundle_dir  # from previous cell\n",
        "\n",
        "# Artifacts\n",
        "with open(f\"{BUNDLE}/config.json\", \"r\") as f:\n",
        "    srv_cfg = json.load(f)\n",
        "srv_tokenizer = AutoTokenizer.from_pretrained(srv_cfg[\"bert_model\"])\n",
        "\n",
        "srv_feature_names = srv_cfg[\"feature_names\"]\n",
        "with open(f\"{BUNDLE}/feature_scaler.json\", \"r\") as f:\n",
        "    srv_scaler_params = json.load(f)\n",
        "srv_mean = np.array(srv_scaler_params[\"mean\"], dtype=np.float32)\n",
        "srv_scale = np.array(srv_scaler_params[\"scale\"], dtype=np.float32)\n",
        "\n",
        "srv_model = BertFeatsClassifier(\n",
        "    bert_name=srv_cfg[\"bert_model\"], feature_dim=len(srv_feature_names),\n",
        "    num_classes=2, feat_hidden=64, dropout_p=0.2, freeze_bert=False\n",
        ").to(device)\n",
        "srv_model.load_state_dict(torch.load(f\"{BUNDLE}/best_model.pt\", map_location=device))\n",
        "srv_model.eval()\n",
        "\n",
        "def srv_standardize(vec):\n",
        "    return (vec - srv_mean) / (srv_scale + 1e-8)\n",
        "\n",
        "def srv_vectorize(feat_dict: dict):\n",
        "    return np.array([float(feat_dict.get(n, 0.0)) for n in srv_feature_names], dtype=np.float32)\n",
        "\n",
        "def srv_tokenize(text: str, max_length: int):\n",
        "    enc = srv_tokenizer([text], padding=\"max_length\", truncation=True, max_length=max_length, return_attention_mask=True)\n",
        "    ids = torch.tensor(enc[\"input_ids\"], dtype=torch.long).to(device)\n",
        "    mask = torch.tensor(enc[\"attention_mask\"], dtype=torch.long).to(device)\n",
        "    return ids, mask\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "class PredictReq(BaseModel):\n",
        "    text: str\n",
        "    threshold: float = 0.50\n",
        "\n",
        "@app.get(\"/health\")\n",
        "def health():\n",
        "    return {\"status\": \"ok\", \"model\": srv_cfg[\"bert_model\"], \"max_length\": srv_cfg[\"max_length\"]}\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "def predict(req: PredictReq):\n",
        "    feats = extract_features(req.text)\n",
        "    vec = srv_vectorize(feats)\n",
        "    vec_std = srv_standardize(vec)\n",
        "    ids, mask = srv_tokenize(req.text, srv_cfg[\"max_length\"])\n",
        "    with torch.no_grad():\n",
        "        logits = srv_model(ids, mask, torch.tensor(vec_std, dtype=torch.float, device=device).unsqueeze(0))\n",
        "        pr = F.softmax(logits, dim=1).cpu().numpy()[0]\n",
        "    prob_real, prob_fake = float(pr[0]), float(pr[1])\n",
        "    label = \"fake\" if prob_fake >= req.threshold else \"real\"\n",
        "    return {\n",
        "        \"label\": label,\n",
        "        \"prob_fake\": prob_fake,\n",
        "        \"prob_real\": prob_real,\n",
        "        \"threshold_used\": req.threshold,\n",
        "        \"top_signals\": top_signals(feats, 3)\n",
        "    }\n",
        "\n",
        "# To run the server in Colab environment (for local testing):\n",
        "# NOTE: In Colab, you'll need ngrok or gradio to expose externally; locally, just run uvicorn.\n",
        "# uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "print(\"FastAPI app ready. Run with: uvicorn.run(app, host='0.0.0.0', port=8000)\")\n"
      ],
      "metadata": {
        "id": "uFPcRzpmXLSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "_m7G5BiTtGSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download cloudflared Linux binary & make it executable\n",
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O cloudflared\n",
        "!chmod +x cloudflared\n",
        "\n",
        "# Sanity: show version (optional)\n",
        "!./cloudflared --version\n"
      ],
      "metadata": {
        "id": "FPh6lhIE1shT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import threading, uvicorn, time\n",
        "\n",
        "# Start uvicorn in a background thread so the cell doesn't block\n",
        "def run_server():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n",
        "\n",
        "server_thread = threading.Thread(target=run_server, daemon=True)\n",
        "server_thread.start()\n",
        "\n",
        "# Give the server a moment to boot\n",
        "time.sleep(2)\n",
        "print(\"✅ Uvicorn started on http://0.0.0.0:8000\")\n"
      ],
      "metadata": {
        "id": "UjrPcoF55KiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess, re, sys, time, threading\n",
        "\n",
        "public_url = None\n",
        "\n",
        "proc = subprocess.Popen(\n",
        "    [\"./cloudflared\", \"tunnel\", \"--url\", \"http://localhost:8000\", \"--no-autoupdate\"],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    text=True,\n",
        "    bufsize=1\n",
        ")\n",
        "\n",
        "def reader():\n",
        "    global public_url\n",
        "    for line in proc.stdout:\n",
        "        sys.stdout.write(line)  # stream logs to cell output\n",
        "        m = re.search(r\"(https://[a-z0-9-]+\\.trycloudflare\\.com)\", line)\n",
        "        if m and public_url is None:\n",
        "            public_url = m.group(1)\n",
        "\n",
        "t = threading.Thread(target=reader, daemon=True)\n",
        "t.start()\n",
        "\n",
        "# wait up to 60s for URL\n",
        "for _ in range(60):\n",
        "    if public_url:\n",
        "        break\n",
        "    time.sleep(1)\n",
        "\n",
        "print(\"\\n🌍 Public URL:\", public_url if public_url else \"Not found yet\")\n"
      ],
      "metadata": {
        "id": "QmXJxIDa5Y5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, json\n",
        "print(\"GET\", public_url + \"/health\")\n",
        "print(json.dumps(requests.get(public_url + \"/health\").json(), indent=2))\n"
      ],
      "metadata": {
        "id": "EgS_pmqv5e7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "XJykep_C5ia8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}